{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b31c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bbdcfa",
   "metadata": {},
   "source": [
    "### Python-dotnev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b28fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44b5ab",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46125be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99af995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is a theory that describes nature on the smallest scales, explaining the behavior of matter and energy on the atomic and subatomic level.\n"
     ]
    }
   ],
   "source": [
    "output = llm('explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322cce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AI LLM stands for Artificial Intelligence Law and Legal Master’s. It is a Master’s degree program that focuses on teaching students the legal aspects of the use of AI technology. The program covers topics such as data privacy, cybercrime, intellectual property, and the ethical implications of using AI in the legal system.\n"
     ]
    }
   ],
   "source": [
    "output = llm(\"What is AI LLM?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b35e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b10712",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['... is the capital of France.', 'What is the formula for the area of a circle?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8432cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\nParis.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where \"A\" is the area, \"π\" is the mathematical constant pi (approximately 3.14159), and \"r\" is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e200aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris.\n"
     ]
    }
   ],
   "source": [
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b7d258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa72bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate([\"Write an original tagline for burger restaurant\"] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b33001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\n\"Taste the Difference at Our Burger Joint - Where Every Bite is Juicy Goodness!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n\"Taste the Deliciousness of Our Burgers - We\\'ll Leave You Wanting More!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n\"Taste the Difference at Our Burger Joint - Juicy Burgers, Fresh Toppings!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfbdbb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taste the Difference at Our Burger Joint - Where Every Bite is Juicy Goodness!\"\n",
      "\n",
      "\"Taste the Deliciousness of Our Burgers - We'll Leave You Wanting More!\"\n",
      "\n",
      "\"Taste the Difference at Our Burger Joint - Juicy Burgers, Fresh Toppings!\""
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b15e29",
   "metadata": {},
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0498214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07974146",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German'),\n",
    "    HumanMessage(content='explain quantum mechanics in one sentence')\n",
    "]\n",
    "\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c5f38be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Quantenmechanik beschreibt das Verhalten von Teilchen auf subatomarer Ebene und ermöglicht es uns, ihre Eigenschaften und Interaktionen mathematisch zu modellieren und vorherzusagen.' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c6ba0a",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff3450cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0abb6857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['virus', 'language'] output_parser=None partial_variables={} template='You are an experienced virologist.\\nWrite a few sentences about the following {virus} in {language}.' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"virus\", \"language\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff7de252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ebola este o boală gravă, cauzată de un virus Ebola, care poate provoca un sindrom hemoragic sever. Simptomele includ febră, durere abdominală, vărsături, diaree și eșecul organelor. Boala a fost descoperită pentru prima dată în 1976, iar cazurile s-au răspândit în Africa, în special în Africa de Vest. În prezent, există tratamente experimentale pentru Ebola, dar vaccinurile sunt în curs de dezvoltare. Controlul infecțiilor este esențial pentru prevenirea răspândirii bolii și tratarea pacienților afectați.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus=\"ebola\", language=\"romainian\"))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53f77889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "إن الفيروس المسبب لمرض نقص المناعة البشرية (HIV) يعتبر من أكثر الفيروسات الخطيرة اثنين، ولهذا فإن الكشف السريع والعلاج المناسب له يعدان من أهم الأولويات في مجال الطب العام. وتتضمن فئات مختلفة من المصادر المحتملة لإصابة بهذا الفيروس، فرادى، أو عن طريق الجهاز التنفس\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus=\"HIV\", language=\"arabic\"))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc73e5",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb355e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7)\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"virus\", \"language\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': \"HSV\", \"language\": \"english\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a64aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSV, or herpes simplex virus, is a highly contagious virus that primarily causes oral or genital herpes. It is classified into two types: HSV-1, which generally causes infections above the waist, including cold sores, and HSV-2, which is mainly responsible for genital herpes. The virus is transmitted through direct contact with infected individuals or through contact with their bodily fluids. Although HSV infections are generally not life-threatening, they can cause significant discomfort and recurrent outbreaks. Treatment options include antiviral medications to manage symptoms and reduce the frequency of outbreaks.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b094bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def linear_regression(x, y):\n",
      "    # find the mean of x and y\n",
      "    x_mean = sum(x)/len(x)\n",
      "    y_mean = sum(y)/len(y)\n",
      "    \n",
      "    # calculate the differences between each x and the mean\n",
      "    x_diff = [x_i - x_mean for x_i in x]\n",
      "    \n",
      "    # calculate the differences between each y and the mean\n",
      "    y_diff = [y_i - y_mean for y_i in y]\n",
      "    \n",
      "    # calculate the numerator and denominator of the slope\n",
      "    numerator = sum([x_diff[i] * y_diff[i] for i in range(len(x))])\n",
      "    denominator = sum([x_diff[i]**2 for i in range(len(x))])\n",
      "    \n",
      "    # calculate the slope\n",
      "    slope = numerator / denominator\n",
      "    \n",
      "    # calculate the intercept\n",
      "    intercept = y_mean - (slope * x_mean)\n",
      "    \n",
      "    # return the slope and intercept\n",
      "    return slope, intercept\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThis Python function calculates the linear regression coefficients, slope and intercept, given two sets of data points, x and y.\n",
      "\n",
      "Here is a step-by-step breakdown of what the function does:\n",
      "\n",
      "1. Calculates the mean of x and y: The function sums up all the elements in x and y respectively and divides them by the length of x and y, giving the mean values x_mean and y_mean.\n",
      "\n",
      "2. Calculates the differences between each x and the mean: The function subtracts the mean value x_mean from each element in x and creates a new list, x_diff, containing the differences.\n",
      "\n",
      "3. Calculates the differences between each y and the mean: Similar to step 2, the function subtracts the mean value y_mean from each element in y and creates a new list, y_diff, containing the differences.\n",
      "\n",
      "4. Calculates the numerator and denominator of the slope: The function uses a list comprehension to iterate over the index i of each element in x and calculates the product of the corresponding elements in x_diff and y_diff, and sums them up as the numerator. The denominator is calculated by squaring each element in x_diff using another list comprehension and summing them up.\n",
      "\n",
      "5. Calculates the slope: Divides the numerator by the denominator to get the slope.\n",
      "\n",
      "6. Calculates the intercept: Uses the formula y_mean - (slope * x_mean) to calculate the intercept.\n",
      "\n",
      "7. Returns the slope, intercept: Returns the values of slope, intercept calculated in steps 5 and 6.\n",
      "\n",
      "Overall, this function calculates the linear regression parameters using the least squares method, which allows for the estimation of a linear relationship between two sets of data points, x and y.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='''Given the Python function {function}, describe it as detailed as possible.'''\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(llm = llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6026b5",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22ab94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9de919db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to calculate this\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'146306.05007233328'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "# agent_executor.run('Calculate the square root of the factorial of 20 \\\n",
    "# and display it with 4 decimal points')\n",
    "\n",
    "agent_executor.run(\"what is the answer to 5.1 ** 7.3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5f76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d57be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b6b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6269500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6b9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467f8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0e483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d72581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0055fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbba21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0424a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a408e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383955ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c056293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc60ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6c57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a28dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b351d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7362f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bfae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67887807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224fd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39eda67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021cb75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa8eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857657c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ce150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b95437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
